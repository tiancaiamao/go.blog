<h2>我们为什么需要大事务</h2><p>用户是有大事务的需求的</p><p>开启 batch dml 以后，无法保证事务的完整性</p><h2>为什么当前不支持大事务</h2><ul><li><p>tikv 扛不住?</p><p>titan 对单个大的 key-value 的支持能力已经大大增强
prewrite 是按 region 的，单个 region 并没多大
我们可以先假设底层引擎是扛得住的</p></li><li><p>TTL 太小事务被干掉</p><p>事务的 primary lock 里面记录了事务状态，有一个 TTL 用于异常处理
TTL 的值太小，在 prewrite 过程中，事务就会被清锁干掉
TTL 设置的太大，会阻塞其它事务
如果事务异常挂掉，锁会很久清不掉，会一直 block 导致其它事务超时失败
解决方案：自动更新 TTL</p></li><li><p>事务的阻塞</p><p>写写冲突，没法解决
读写冲突，<strong>只要让大事务不阻塞读操作，就可以接受</strong>
解决方案：新的事务模型</p></li><li><p>事务冲突代价太高</p><p>不在解决范围之内
或者可以考虑悲观事务</p></li></ul><h2>TTL 自动更新</h2><p>初始设置一个比较短的事务 TTL，然后在事务存活期间，自动更新 primary lock 的 TTL 值</p><p>这样就可以解决大事务的 TTL 问题</p><ul><li>TTL 自动更新导致 ResolveLock 需要调整</li><li>TTL 自动更新需要引入死锁检测</li></ul><h3>死锁检测</h3><p>乐观锁里面不需要死锁检测，因为 TTL 不会更新，即使发生了死锁，过了 TTL 锁也能清掉</p><p>自动更新 TTL 之后，需要引入死锁检测</p><h2>ResolveLock</h2><p>以前检查 secondary lock 跟检查 primary lock 都一样</p><p>操作步骤：</p><ul><li>检查到 secondary(primary) lock</li><li>backoff TTL 那么久</li><li>调用 CleanUp 将 primary lock 给 Rollback</li><li>调用 ResolveLock 清理 secondary lock</li></ul><p>现在 secondary lock 里面信息无效，只有 primary lock 里面是真实的</p><ul><li>检查到 secondary(primary) lock</li><li>去检查 primary lock 判定事务状态 (CheckTxnStatus)</li><li>如果事务 TTL 过期，则清锁</li><li>如果事务 TTL 没过期，则 backoff 之后重新检查</li></ul><h3>CheckTxnStatus 两种异常场景</h3><p>遇到 secondary lock 了，再去检查 primary lock，发现 primary lock 不存在。</p><p>什么情况下会遇到？</p><ul><li>由于 prewrite region 并发，secondary lock 先写成功，primary lock 还没写</li><li>由于悲观锁回滚不留下 tombstone</li></ul><h2>非阻塞读</h2><h3>为什么遇锁会阻塞读操作</h3><p>一个事务正在写入，另一个事务去读取。能不能读正在写的内容？</p><ul><li>读了，事务回滚了 -- read uncommitted</li><li>不读，事务成功了 -- lost update</li></ul><p>读不读都有问题，所以要：等。</p><p>等写操作执行完了再读，就没这个麻烦了。</p><h3>事务顺序</h3><p>从第二个点想想办法，我们讨论不读</p><p>如果写事务在前面，读事务在后面，不读就会出现写丢失。</p><p>所以 <strong>关键点是重排序，让读事务在前面，写事务到后面</strong>，这样读事务就可以不读到写事务</p><p>如何调整事务顺序呢？ 事务顺序是由 ts 决定的。</p><p><em>一个事务1的 start ts 大于另一个事务2的 commit ts，那么事务1是在事务2 后面的</em></p><p>假设每个 ts 都唯一，并且不考虑 +-1 问题，我们可以换一种说法：</p><p><em>一个事务1的 start ts 小于另一个事务2的 commit ts，那么事务1是在事务2 前面的</em></p><p>所以让读事务，把写事务的 commit ts 往后推，保证读事务 start ts 小于写事务 commit ts</p><p>即可达成顺序调整，从而实现重排序</p><h3>min commit ts</h3><ul><li><p>在 primary lock 里面，记录一个 minCommitTS 字段</p></li><li><p>每次读者遇到锁的时候，调整 minCommitTS，使它大于 reader ts</p></li><li><p>commit 的时候，最终 commit ts 要至少大于 minCommitTS</p></li></ul><p>即：<strong>每次读事务，遇到写事务，读事务会把写事务推到自己后面</strong></p><h2>测试中遇到哪些问题</h2><h3>并发压力过大，tikv 被打死了</h3><p>prewrite 的时候，按 region 数量并发</p><p>大事务需要控制并发量，否则 tikv 会被打死</p><h3>insert 执行慢</h3><p>coprocessor 是并行读的</p><p>insert 的时候是串行的</p><p>在 insert 那里会形成一个瓶颈点，大事务比较明显</p><h3>内存问题</h3><p>memdb 是大块连续内存，在大事务下会分配失败 =&gt; 改造成分块的，每块大小上限 128M</p><p>insert 过程中，table 接口是用的 []Datum 表示，非常占内存 =&gt; 改成尽快刷到 memdb 里面</p><p>2pc 里面 mutation 的内存占用高</p><p>纯 KV 数据量 2-3G 的大事务，在 mutation 里面的表示大概 7-8G</p><p>加上其它包括 dirty table 和进程本身之类会到 10G</p><p>由于 Go 的 GC 策略，向系统申请的内存量会在 20G</p><p>大概 6 倍的放大</p><p>预计支持 10G 事务需要 60G+ 的内存</p><p>2-3G 的事务完成时间大概是 10min</p>